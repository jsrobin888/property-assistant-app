# Property Management Email Assistant

**An AIâ€‘powered FastAPI service that triages propertyâ€‘management eâ€‘mails, generates LLM replies, and turns actionable items into support tickets â€“ all through a clean JSON/REST interface.**


---

## âœ¨ Key Features

* **Eâ€‘mail ingestion** â€“ fetch unread or recent messages directly from Gmail via the `/workflows/fetch-gmail` endpoint.
* **AI response generation** â€“ LangChain + OpenAI / Anthropic / Ollama models propose multiple reply options, stored in a *waiting zone* for human review.
* **Actionâ€‘item extraction** â€“ converts bulletâ€‘point action items in the eâ€‘mail body into structured JSON.
* **Ticket creation** â€“ pushes selected action items into the internal ticket system (`/tickets/*`).
* **Workflow API** â€“ single endpoint (`POST /workflows/process-emails`) triggers the full pipeline from fetch â†’ AI reply â†’ ticket.
* **Health & analytics** â€“ builtâ€‘in `/health` and `/emails/analytics/summary` endpoints plus TinyDB/SQLAlchemy stats.
* **Pluggable vector search** â€“ optional FAISS + sentenceâ€‘transformers for semantic lookâ€‘ups.
* **Async & background tasks** â€“ APScheduler + Celery + Redis keep longâ€‘running jobs out of the request loop.

---

## ðŸ—ï¸ Techâ€‘Stack

| Layer                 | Details                                                        |
| --------------------- | -------------------------------------------------------------- |
| **API**               | FastAPIÂ (uvicorn hotâ€‘reload)                                   |
| **LLM**               | LangChain wrappers for OpenAI, Anthropic, Ollama, HuggingÂ Face |
| **Persistence**       | TinyDB (default dev DB) â€¢ PostgreSQL (via SQLAlchemy)          |
| **Queue / Scheduler** | Celery â€¢ Redis â€¢ APScheduler                                   |
| **Vector Store**      | FAISSâ€‘CPU                                                      |
| **Testing & Tooling** | (TBD) pytest, ruff, black,                                     |

---

## âš¡ QuickÂ Start

> **TL;DR** â€“ three commands and youâ€™re in the docs at [http://localhost:8000/docs](http://localhost:8000/docs).

```bash
# 1. Clone & enter
git clone https://github.com/jsrobin888/property-assistant-app.git
cd property-assistant-app

# 2. Python env & deps  (â‰ˆ30Â s with uv)
uv venv           # creates .venv
uv pip install -r requirements.txt
cp .env.local.copy .env.local   # fill in API keys: OPENAI_API_KEY, GMAIL_* â€¦

# 3. Run the API
source .venv/bin/activate       # Windows: .venv\\Scripts\\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

**FYI: Wait until shows "INFO:     Application startup complete."
```

The interactive swagger UI will be available at [http://localhost:8000/docs](http://localhost:8000/docs) and ReDoc at `/redoc`.

### Oneâ€‘line sanity check

```bash
python -c "import langchain_openai, numpy, fastapi, torch; print('âœ… env looks good')"
```

---

## ðŸ”Œ Environment Variables

| Variable                                  | What for        | Example                                   |
| ----------------------------------------- | --------------- | ----------------------------------------- |
| `OPENAI_API_KEY`                          | LLM replies     | `skâ€‘â€¦`                                    |
| `ANTHROPIC_API_KEY`                       | optional        |                                           |
| `DATABASE_URL`                            | Postgres (prod) | `postgresql+psycopg2://user:pass@host/db` |
| `REDIS_URL`                               | optional        | `redis://localhost:6379/0`                |
| `GMAIL_IMAP_HOST`, `GMAIL_USERNAME`, `GMAIL_PASSWORD`       | IMAP/GMAIL auth |   |
| `SCHEDULER_MODE`                          | CRON Scheduler  | |
| `USE_LOCAL_MODELS`                        | LLM Ollama      | boolean `true` or `false` |
| `LOCAL_AI_BASE_URL`                      | LLM Ollama      | `http://0.0.0.0:11434`    |
| `LOG_LEVEL`                               | logging         |   |
| `LOADER_VERIFICATION`                     | logging         |   |
For local hacking you can leave **DATABASE\_URL** empty to fall back to inâ€‘memory TinyDB.

---

## ðŸ›°ï¸ API Cheatsheet

| Endpoint                              | Verb   | Description                                  |
| ------------------------------------- | ------ | -------------------------------------------- |
| `/api/v1/workflows/process-emails`    | `POST` | Run full ingestÂ â†’Â AIÂ â†’Â ticket pipeline       |
| `/api/v1/workflows/fetch-gmail`       | `POST` | Pull unread / recent / countâ€‘limited eâ€‘mails |
| `/api/v1/workflows/status/{{id}}`     | `GET`  | Check backgroundâ€‘workflow progress           |
| `/api/v1/emails/ai-responses/pending` | `GET`  | List AI replies awaiting approval            |
| `/api/v1/tickets/`                    | `GET`  | Filter & search tickets                      |
| `/health`                             | `GET`  | Service heartbeat                            |

*(see `app/api/routes.py` for the full list)*

---

## ðŸ³ Docker (optional)

```bash
[Optional] docker-compose down -v 
docker-compose up --build
```

---

## ðŸ§ª Quick Tests (optional)

```bash
python -c "import langchain_openai; print('âœ… LangChain OpenAI installed')"
python -c "import langchain_huggingface; print('âœ… LangChain HuggingFace installed')"
python -c "import sentence_transformers; print('âœ… Sentence Transformers installed')"
python -c "import numpy; print(f'âœ… NumPy {numpy.__version__}')"
python -m app.examples.use_cases.integration_cases full
```


---

## ðŸ¤ Contributing

1. Fork â†’ feature branch â†’ PR
2. Ensure `pytest`, `ruff`, and `black` pass
3. Document new endpoints in **README** and `/docs`

---

## ðŸ“œ License

This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.

---

> *Happy automating property management!*
